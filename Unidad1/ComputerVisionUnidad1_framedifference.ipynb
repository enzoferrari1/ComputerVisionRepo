{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Computer Vision\n",
        "## Práctica Unidad 1\n",
        "### Primer Ejercicio\n",
        "Genere un video en un patio o en un hall de edificio donde en un principio se vea vacío y luego aparezca una persona. Primero debemos, de manera similar al trabajo final realizado en PDI 1, detectar el movimiento sin utilizar deep learning, utilizando diferencia de frames, operaciones morfológicas y supresión de no máximos para obtener una colección de bounding boxes que indiquen los objetos en movimiento en el video.\n",
        "\n",
        "Para esta parte, utilizamos el repositorio\n",
        "https://github.com/itberrios/CV_projects/blob/main/motion_detection/detection_with_frame_differencing.ipynb"
      ],
      "metadata": {
        "id": "CfteYS1pfC9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "REPO_NAME = \"ComputerVisionRepo\"\n",
        "if REPO_NAME not in os.getcwd():\n",
        "  if not os.path.exists(REPO_NAME):\n",
        "    !git clone https://github.com/enzoferrari1/ComputerVisionRepo.git\n",
        "  os.chdir(REPO_NAME + '/Unidad1/')\n",
        "\n"
      ],
      "metadata": {
        "id": "LvxWaNrL4rNo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos todas las funciones a utilizar"
      ],
      "metadata": {
        "id": "0GkaIkAHp9pS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4bhbuIbDe2Jm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import re\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "def get_mask(frame1, frame2, kernel=np.array((9,9), dtype=np.uint8)):\n",
        "    \"\"\" Obtains image mask\n",
        "        Inputs:\n",
        "            frame1 - Grayscale frame at time t\n",
        "            frame2 - Grayscale frame at time t + 1\n",
        "            kernel - (NxN) array for Morphological Operations\n",
        "        Outputs:\n",
        "            mask - Thresholded mask for moving pixels\n",
        "        \"\"\"\n",
        "    frame_diff = cv2.subtract(frame2, frame1)\n",
        "\n",
        "    # blur the frame difference\n",
        "    frame_diff = cv2.medianBlur(frame_diff, 3)\n",
        "\n",
        "    mask = cv2.adaptiveThreshold(frame_diff, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
        "                cv2.THRESH_BINARY_INV, 11, 3)\n",
        "\n",
        "    mask = cv2.medianBlur(mask, 3)\n",
        "\n",
        "    # morphological operations\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
        "\n",
        "    return mask\n",
        "\n",
        "def get_contour_detections(mask, thresh=400):\n",
        "    \"\"\" Obtains initial proposed detections from contours discoverd on the mask.\n",
        "        Scores are taken as the bbox area, larger is higher.\n",
        "        Inputs:\n",
        "            mask - thresholded image mask\n",
        "            thresh - threshold for contour size\n",
        "        Outputs:\n",
        "            detectons - array of proposed detection bounding boxes and scores [[x1,y1,x2,y2,s]]\n",
        "        \"\"\"\n",
        "    # get mask contours\n",
        "    contours, _ = cv2.findContours(mask,\n",
        "                                   cv2.RETR_EXTERNAL, # cv2.RETR_TREE,\n",
        "                                   cv2.CHAIN_APPROX_TC89_L1)\n",
        "    detections = []\n",
        "    for cnt in contours:\n",
        "        x,y,w,h = cv2.boundingRect(cnt)\n",
        "        area = w*h\n",
        "        if area > thresh: # hyperparameter\n",
        "            detections.append([x,y,x+w,y+h, area])\n",
        "\n",
        "    return np.array(detections)\n",
        "\n",
        "def compute_iou(box1, box2):\n",
        "    \"\"\" Obtains Intersection over union (IOU) of 2 bounding boxes\n",
        "        Inputs are in the form of:\n",
        "            xmin, ymin, xmax, ymax = box\n",
        "        \"\"\"\n",
        "    x11, y11, x21, y21 = box1\n",
        "    x12, y12, x22, y22 = box2\n",
        "\n",
        "    # get box points of intersection\n",
        "    xi1 = max(x11, x12) # top left\n",
        "    yi1 = max(y11, y12)\n",
        "    xi2 = min(x21, x22) # bottom right\n",
        "    yi2 = min(y21, y22)\n",
        "\n",
        "    # compute intersectional area\n",
        "    inter_area = max((xi2 - xi1 + 1), 0) * max((yi2 - yi1 + 1), 0)\n",
        "    if inter_area == 0:\n",
        "        return inter_area\n",
        "\n",
        "    # compute box areas\n",
        "    box1_area = (x21 - x11 + 1) * (y21 - y11 + 1)\n",
        "    box2_area = (x22 - x12 + 1) * (y22 - y12 + 1)\n",
        "\n",
        "    # return iou\n",
        "    return inter_area / (box1_area + box2_area - inter_area)\n",
        "\n",
        "def get_inter_area(box1, box2):\n",
        "    \"\"\"\n",
        "    Obtains bounding box for intersection area of two boundning boxes\n",
        "    Inputs are in the form of:\n",
        "            xmin, ymin, xmax, ymax = box\n",
        "    \"\"\"\n",
        "    x11, y11, x21, y21 = box1\n",
        "    x12, y12, x22, y22 = box2\n",
        "\n",
        "    # get box points of intersection\n",
        "    xi1 = max(x11, x12) # top left\n",
        "    yi1 = max(y11, y12)\n",
        "    xi2 = min(x21, x22) # bottom right\n",
        "    yi2 = min(y21, y22)\n",
        "\n",
        "    # compute intersectional area\n",
        "    inter_area = max((xi2 - xi1 + 1), 0) * max((yi2 - yi1 + 1), 0)\n",
        "    if inter_area == 0:\n",
        "        return 0, 0, 0, 0\n",
        "\n",
        "    return xi1, yi1, xi2, yi2\n",
        "\n",
        "def remove_contained_bboxes(boxes):\n",
        "    \"\"\" Removes all smaller boxes that are contained within larger boxes.\n",
        "        Requires bboxes to be soirted by area (score)\n",
        "        Inputs:\n",
        "            boxes - array bounding boxes sorted (descending) by area\n",
        "                    [[x1,y1,x2,y2]]\n",
        "        Outputs:\n",
        "            keep - indexes of bounding boxes that are not entirely contained\n",
        "                   in another box\n",
        "        \"\"\"\n",
        "    check_array = np.array([True, True, False, False])\n",
        "    keep = list(range(0, len(boxes)))\n",
        "    for i in keep: # range(0, len(bboxes)):\n",
        "        for j in range(0, len(boxes)):\n",
        "            # check if box j is completely contained in box i\n",
        "            if np.all((np.array(boxes[j]) >= np.array(boxes[i])) == check_array):\n",
        "                try:\n",
        "                    keep.remove(j)\n",
        "                except ValueError:\n",
        "                    continue\n",
        "    return keep\n",
        "\n",
        "\n",
        "def non_max_suppression(boxes, scores, threshold=1e-1):\n",
        "    \"\"\"\n",
        "    Perform non-max suppression on a set of bounding boxes and corresponding scores.\n",
        "    Inputs:\n",
        "        boxes: a list of bounding boxes in the format [xmin, ymin, xmax, ymax]\n",
        "        scores: a list of corresponding scores\n",
        "        threshold: the IoU (intersection-over-union) threshold for merging bounding boxes\n",
        "    Outputs:\n",
        "        boxes - non-max suppressed boxes\n",
        "    \"\"\"\n",
        "    # Sort the boxes by score in descending order\n",
        "    boxes = boxes[np.argsort(scores)[::-1]]\n",
        "\n",
        "    # remove all contained bounding boxes and get ordered index\n",
        "    order = remove_contained_bboxes(boxes)\n",
        "\n",
        "    keep = []\n",
        "    while order:\n",
        "        i = order.pop(0)\n",
        "        keep.append(i)\n",
        "        for j in order:\n",
        "            # Calculate the IoU between the two boxes\n",
        "            intersection = max(0, min(boxes[i][2], boxes[j][2]) - max(boxes[i][0], boxes[j][0])) * \\\n",
        "                           max(0, min(boxes[i][3], boxes[j][3]) - max(boxes[i][1], boxes[j][1]))\n",
        "            union = (boxes[i][2] - boxes[i][0]) * (boxes[i][3] - boxes[i][1]) + \\\n",
        "                    (boxes[j][2] - boxes[j][0]) * (boxes[j][3] - boxes[j][1]) - intersection\n",
        "            iou = intersection / union\n",
        "\n",
        "            # Remove boxes with IoU greater than the threshold\n",
        "            if iou > threshold:\n",
        "                order.remove(j)\n",
        "\n",
        "    return boxes[keep]\n",
        "\n",
        "def non_max_suppression_2(boxes, scores, threshold=1e-1):\n",
        "    \"\"\"\n",
        "    Perform non-max suppression on a set of bounding boxes and corresponding scores.\n",
        "    NOTE: Eventhough we only go through 2 loops here, this way is more complicated and slower!\n",
        "    Inputs:\n",
        "        boxes: a list of bounding boxes in the format [xmin, ymin, xmax, ymax]\n",
        "        scores: a list of corresponding scores\n",
        "        threshold: the IoU (intersection-over-union) threshold for merging bounding boxes\n",
        "    Outputs:\n",
        "        boxes - non-max suppressed boxes\n",
        "    \"\"\"\n",
        "    # Sort the boxes by score in descending order\n",
        "    boxes = boxes[np.argsort(scores)[::-1]]\n",
        "\n",
        "    keep = list(range(0, len(boxes)))\n",
        "    for i in keep:\n",
        "        for j in range(0, len(bboxes)):\n",
        "            # check if box j is completely contained in box i\n",
        "            if np.all((np.array(boxes[j]) >= np.array(boxes[i])) == np.array([True, True, False, False])):\n",
        "                try:\n",
        "                    keep.remove(j)\n",
        "                except ValueError:\n",
        "                    continue\n",
        "            # if no overlap check IOU threshold\n",
        "            else:\n",
        "                # Calculate the IoU between the two boxes\n",
        "                intersection = max(0, min(boxes[i][2], boxes[j][2]) - max(boxes[i][0], boxes[j][0])) * \\\n",
        "                            max(0, min(boxes[i][3], boxes[j][3]) - max(boxes[i][1], boxes[j][1]))\n",
        "                union = (boxes[i][2] - boxes[i][0]) * (boxes[i][3] - boxes[i][1]) + \\\n",
        "                        (boxes[j][2] - boxes[j][0]) * (boxes[j][3] - boxes[j][1]) - intersection\n",
        "                iou = intersection / union\n",
        "\n",
        "                # Remove boxes with IoU greater than the threshold\n",
        "                # ensure that we don't remove larger boxes by checking (j > i)\n",
        "                if (iou > threshold) and (j > i):\n",
        "                    try:\n",
        "                        keep.remove(j)\n",
        "                    except ValueError:\n",
        "                        continue\n",
        "    return boxes[keep]\n",
        "\n",
        "def get_detections(frame1, frame2, bbox_thresh=400, nms_thresh=1e-3, mask_kernel=np.array((9,9), dtype=np.uint8)):\n",
        "    \"\"\" Main function to get detections via Frame Differencing\n",
        "        Inputs:\n",
        "            frame1 - Grayscale frame at time t\n",
        "            frame2 - Grayscale frame at time t + 1\n",
        "            bbox_thresh - Minimum threshold area for declaring a bounding box\n",
        "            nms_thresh - IOU threshold for computing Non-Maximal Supression\n",
        "            mask_kernel - kernel for morphological operations on motion mask\n",
        "        Outputs:\n",
        "            detections - list with bounding box locations of all detections\n",
        "                bounding boxes are in the form of: (xmin, ymin, xmax, ymax)\n",
        "        \"\"\"\n",
        "    try:\n",
        "      # get image mask for moving pixels\n",
        "      mask = get_mask(frame1, frame2, mask_kernel)\n",
        "\n",
        "      # get initially proposed detections from contours\n",
        "      detections = get_contour_detections(mask, bbox_thresh)\n",
        "      print(type(detections))\n",
        "      print(detections.shape)\n",
        "\n",
        "      # separate bboxes and scores\n",
        "      bboxes = detections[:, :4]\n",
        "      scores = detections[:, -1]\n",
        "\n",
        "      # perform Non-Maximal Supression on initial detections\n",
        "      return non_max_suppression(bboxes, scores, nms_thresh)\n",
        "    except IndexError:\n",
        "      # En caso de que no se encuentren detecciones, devolvemos None y manejamos este caso en el pipeline\n",
        "      return None\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos el pipeline"
      ],
      "metadata": {
        "id": "Cs39zDjGqAq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "\n",
        "def draw_bboxes(frame, detections):\n",
        "    for det in detections:\n",
        "        x1,y1,x2,y2 = det\n",
        "        cv2.rectangle(frame, (x1,y1), (x2,y2), (0,255,0), 3)\n",
        "\n",
        "\n",
        "def create_gif_from_images(save_path : str, image_path : str, ext : str) -> None:\n",
        "    ''' creates a GIF from a folder of images\n",
        "        Inputs:\n",
        "            save_path - path to save GIF\n",
        "            image_path - path where images are located\n",
        "            ext - extension of the images\n",
        "        Outputs:\n",
        "            None\n",
        "    '''\n",
        "    ext = ext.replace('.', '')\n",
        "    image_paths = sorted(glob(os.path.join(image_path, f'*.{ext}')))\n",
        "    image_paths.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
        "    pil_images = [Image.open(im_path) for im_path in image_paths]\n",
        "\n",
        "    pil_images[0].save(save_path, format='GIF', append_images=pil_images,\n",
        "                       save_all=True, duration=50, loop=0)\n",
        ""
      ],
      "metadata": {
        "id": "hhx1D4heqCIz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargamos el video"
      ],
      "metadata": {
        "id": "Of4StT1nsZ_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# Path to the MP4 video file\n",
        "video_path = '/content/ComputerVisionRepo/Unidad1/hallvideo.mp4'\n",
        "\n",
        "# Directory to save the extracted frames\n",
        "output_dir = '/content/output'\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Open the video file\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Initialize a frame counter and frame skip\n",
        "frame_count = 0\n",
        "frame_skip = 5  # Number of frames to skip\n",
        "\n",
        "# Set the frame position to skip frames\n",
        "cap.set(cv2.CAP_PROP_POS_FRAMES, frame_skip)\n",
        "\n",
        "# Loop through the video frames\n",
        "while cap.isOpened():\n",
        "    # Read a frame from the video\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Check if the frame was read successfully\n",
        "    if ret:\n",
        "        # Increment the frame counter\n",
        "        frame_count += 1\n",
        "\n",
        "        # Save the frame as an image\n",
        "        frame_filename = os.path.join(output_dir, f\"frame_{frame_count:04d}.jpg\")\n",
        "        cv2.imwrite(frame_filename, frame)\n",
        "\n",
        "        # Set the frame position for the next iteration\n",
        "        frame_skip += 5  # Adjust the frame skip value if needed\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_skip)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "# Release the video capture object\n",
        "cap.release()\n",
        "\n",
        "print(f\"Frames extracted: {frame_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BcKbf-gtOy3",
        "outputId": "b4056440-661c-40dc-c2d6-93c8adaf54b0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frames extracted: 108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths = sorted(glob(f\"{output_dir}/*.jpg\"), key=lambda x:float(re.findall(\"(\\d+)\",x)[0]))\n",
        "image_paths"
      ],
      "metadata": {
        "id": "z6oZ11CPt02w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_frames = []\n",
        "# Directory to save the extracted frames\n",
        "output_dir = '/content/final_output'\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for idx in range(1, len(image_paths)):\n",
        "    # read frames\n",
        "    print(idx)\n",
        "    frame1_bgr = cv2.imread(image_paths[idx - 1])\n",
        "    frame2_bgr = cv2.imread(image_paths[idx])\n",
        "\n",
        "    # get detections\n",
        "    detections = get_detections(cv2.cvtColor(frame1_bgr, cv2.COLOR_BGR2GRAY),\n",
        "                                cv2.cvtColor(frame2_bgr, cv2.COLOR_BGR2GRAY),\n",
        "                                bbox_thresh=400,\n",
        "                                nms_thresh=1e-4)\n",
        "    # Check if detections are empty\n",
        "    if detections is None:\n",
        "        print(\"No detections found for frame\", idx)\n",
        "        # Save the frame without drawing bounding boxes\n",
        "        frame_filename = f\"/content/final_output/frame_{idx}.png\"\n",
        "        cv2.imwrite(frame_filename, frame2_bgr)\n",
        "        continue  # Skip further processing for this frame\n",
        "\n",
        "    # draw bounding boxes on frame\n",
        "    draw_bboxes(frame2_bgr, detections)\n",
        "\n",
        "    # save image for GIF\n",
        "    fig = plt.figure(figsize=(15, 7))\n",
        "    plt.imshow(frame2_bgr)\n",
        "    plt.axis('off')\n",
        "    fig.savefig(f\"/content/final_output/frame_{idx}.png\")\n",
        "    plt.close();\n",
        "\n",
        "    # OPTIONAL append to list for video\n",
        "    video_frames.append(frame2_bgr)"
      ],
      "metadata": {
        "id": "nG5UmhkmsTFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the dimensions of the first frame\n",
        "frame_height, frame_width, _ = video_frames[0].shape\n",
        "\n",
        "out = cv2.VideoWriter('frame_differencing.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 25, (frame_width, frame_height))\n",
        "\n",
        "for img in video_frames:\n",
        "    # Convert the frame to BGR format if needed\n",
        "    if len(img.shape) == 2:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    out.write(img)\n",
        "\n",
        "out.release()\n"
      ],
      "metadata": {
        "id": "xGYqCGdDxtL_"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6uEQtIs82YUi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}