{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fTbWrNfzf6J",
        "outputId": "eac2ca19-091b-490b-f668-5e0b665e02e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'yolov10'...\n",
            "remote: Enumerating objects: 20329, done.\u001b[K\n",
            "remote: Counting objects: 100% (1527/1527), done.\u001b[K\n",
            "remote: Compressing objects: 100% (176/176), done.\u001b[K\n",
            "remote: Total 20329 (delta 1450), reused 1363 (delta 1351), pack-reused 18802\u001b[K\n",
            "Receiving objects: 100% (20329/20329), 11.19 MiB | 17.46 MiB/s, done.\n",
            "Resolving deltas: 100% (14326/14326), done.\n",
            "/content/yolov10\n",
            "Processing /content/yolov10\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.1.34) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.1.34) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.1.34) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.1.34) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.1.34) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.1.34) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.1.34) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.1.34) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.1.34) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.1.34) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.1.34) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics==8.1.34)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.1.34) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.1.34) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics==8.1.34) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics==8.1.34) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.1.34) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.1.34) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.1.34) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.1.34) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.1.34) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.1.34) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.1.34) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.1.34) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.1.34) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.1.34) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics==8.1.34)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics==8.1.34)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics==8.1.34)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics==8.1.34)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics==8.1.34)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics==8.1.34)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics==8.1.34)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics==8.1.34)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics==8.1.34)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics==8.1.34)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics==8.1.34)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.1.34) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics==8.1.34)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.1.34) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics==8.1.34) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics==8.1.34) (1.3.0)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Building wheels for collected packages: ultralytics\n",
            "  Building wheel for ultralytics (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ultralytics: filename=ultralytics-8.1.34-py3-none-any.whl size=731411 sha256=c77a228db45e2e8981a5bb81afb6ec6005a67723e20fba5215ad4681f7b80982\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bsm9b6tq/wheels/51/93/e8/22d2e815ced343915c15d86b2a00d95eb0a997d012527fbea7\n",
            "Successfully built ultralytics\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238 ultralytics-8.1.34\n"
          ]
        }
      ],
      "source": [
        "# !pip install ultralytics\n",
        "%cd /content\n",
        "!rm -rf yolov10\n",
        "!git clone https://github.com/THU-MIG/yolov10.git\n",
        "%cd yolov10\n",
        "!pip install ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "import gdown\n",
        "!gdown 10cLCR7zdhFY0yn3xCJ2oQ8yee3-VhwZZ\n",
        "!gdown 1DvUO0LtiMxFcgVXNiXL4jSkODaG8Bl1E"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txCn1kqV5111",
        "outputId": "247ace71-f58c-4912-ec23-890196018e99"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=10cLCR7zdhFY0yn3xCJ2oQ8yee3-VhwZZ\n",
            "From (redirected): https://drive.google.com/uc?id=10cLCR7zdhFY0yn3xCJ2oQ8yee3-VhwZZ&confirm=t&uuid=56154cd8-b1ef-406d-bcdf-110046e8a573\n",
            "To: /content/yolov10-card-96p.pt\n",
            "100% 33.4M/33.4M [00:02<00:00, 14.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1DvUO0LtiMxFcgVXNiXL4jSkODaG8Bl1E\n",
            "To: /content/best-classifier-model.keras\n",
            "100% 12.9M/12.9M [00:00<00:00, 20.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov10\n",
        "from ultralytics import YOLOv10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo1s-c5V0dyc",
        "outputId": "dedaba79-1262-4fed-90be-60f9e1d9f207"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# Load a model\n",
        "model = YOLOv10(\"/content/yolov10-card-96p.pt\")  # pretrained YOLOv8n model\n",
        "# Load your Keras classifier model\n",
        "classifier = tf.keras.models.load_model('/content/best-classifier-model.keras')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WklUw9DCLo1L",
        "outputId": "e91e67cb-a033-4d45-af02-b9df20daef2c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ /content/yolov10-card-96p.pt appears to require 'dill', which is not in ultralytics requirements.\n",
            "AutoInstall will run now for 'dill' but this feature will be removed in the future.\n",
            "Recommend fixes are to train a new model using the latest 'ultralytics' package or to run a command with an official YOLOv8 model, i.e. 'yolo predict model=yolov8n.pt'\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['dill'] not found, attempting AutoUpdate...\n",
            "Collecting dill\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 116.3/116.3 kB 35.2 MB/s eta 0:00:00\n",
            "Installing collected packages: dill\n",
            "Successfully installed dill-0.3.8\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 2.4s, installed 1 package: ['dill']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 398 variables whereas the saved optimizer has 2 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Run batched inference on a list of images\n",
        "# results = model(['/content/test-cards-image3.jpg'])  # return a list of Results objects\n",
        "\n",
        "# # Process results list\n",
        "# for result in results:\n",
        "#     boxes = result.boxes  # Boxes object for bounding box outputs\n",
        "#     print(boxes[0])\n",
        "#     masks = result.masks  # Masks object for segmentation masks outputs\n",
        "#     keypoints = result.keypoints  # Keypoints object for pose outputs\n",
        "#     probs = result.probs  # Probs object for classification outputs\n",
        "#     obb = result.obb  # Oriented boxes object for OBB outputs\n",
        "#     result.show()  # display to screen\n",
        "#     result.save(filename=\"result.jpg\")  # save to disk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAIpnxCVKZgy",
        "outputId": "66ab9ab3-0a5b-4222-f75b-5f582c0fa287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 8 cards, 168.9ms\n",
            "Speed: 3.1ms preprocess, 168.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.9332])\n",
            "data: tensor([[517.8418, 383.7551, 691.7391, 534.1752,   0.9332,   0.0000]])\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (1280, 720)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[604.7905, 458.9651, 173.8973, 150.4202]])\n",
            "xywhn: tensor([[0.8400, 0.3586, 0.2415, 0.1175]])\n",
            "xyxy: tensor([[517.8418, 383.7551, 691.7391, 534.1752]])\n",
            "xyxyn: tensor([[0.7192, 0.2998, 0.9607, 0.4173]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizar inferencia\n",
        "%cd /content\n",
        "!gdown 1Kz9xn8Ad6hVuIb0Y_oMlKvUxo8YLuBn4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpqFAlw8r0o2",
        "outputId": "5895c860-3a4a-4ea9-ed3b-b6349ea0004a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1Kz9xn8Ad6hVuIb0Y_oMlKvUxo8YLuBn4\n",
            "From (redirected): https://drive.google.com/uc?id=1Kz9xn8Ad6hVuIb0Y_oMlKvUxo8YLuBn4&confirm=t&uuid=8e525a62-0d75-49c2-b107-bf376d2c7821\n",
            "To: /content/00.alumnes_practico.zip\n",
            "100% 104M/104M [00:02<00:00, 35.0MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/00.alumnes_practico.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYTgbGyczkS3",
        "outputId": "e45c0b41-865e-40fe-bad5-e702e20bfba7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/00.alumnes_practico.zip\n",
            "   creating: 00.alumnes_practico/\n",
            "  inflating: 00.alumnes_practico/README.txt  \n",
            "  inflating: 00.alumnes_practico/00.run_envido.ipynb  \n",
            "   creating: 00.alumnes_practico/data/\n",
            "   creating: 00.alumnes_practico/data/.ipynb_checkpoints/\n",
            "   creating: 00.alumnes_practico/data/eval/\n",
            "  inflating: 00.alumnes_practico/data/eval/gt_envido.json  \n",
            "  inflating: 00.alumnes_practico/data/eval/dataset.yaml  \n",
            "   creating: 00.alumnes_practico/data/eval/images/\n",
            "   creating: 00.alumnes_practico/data/eval/images/train/\n",
            "   creating: 00.alumnes_practico/data/eval/images/val/\n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_173828513_HDR.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_174459285.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_173737533.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_174418639.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_174005265.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_174105714.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_174453153.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_174406256.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_174246178_HDR.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_173711753_HDR.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_174155383_HDR.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_174223161_HDR.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_173822184_HDR.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_174445046_HDR.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_173918579.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_174514649_HDR.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_173836085.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_173954348.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_174208092.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_173859456.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_174133804_HDR.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_174349395.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_174316833.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_174333447.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_174235296.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_174434126.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_174142929_HDR.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_173929084.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_174302382_HDR.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_173758691.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_174115784.jpg  \n",
            "  inflating: 00.alumnes_practico/data/eval/images/val/IMG_20240630_174017809.jpg  \n",
            "   creating: 00.alumnes_practico/data/eval/labels/\n",
            "   creating: 00.alumnes_practico/data/eval/labels/train/\n",
            "   creating: 00.alumnes_practico/data/eval/labels/val/\n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_173836085.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_174459285.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_174333447.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_174514649_HDR.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_174115784.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_174406256.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_174005265.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_173828513_HDR.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_174235296.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_173929084.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_174223161_HDR.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_174418639.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_174302382_HDR.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_174316833.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_173918579.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_173822184_HDR.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_174105714.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_174453153.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_174434126.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_174155383_HDR.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_174445046_HDR.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_174246178_HDR.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_173758691.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_174017809.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_173954348.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_174142929_HDR.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_174349395.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_174208092.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_173737533.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_174133804_HDR.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_173859456.txt  \n",
            "  inflating: 00.alumnes_practico/data/eval/labels/val/IMG_20240630_173711753_HDR.txt  \n",
            "   creating: 00.alumnes_practico/model/\n",
            "   creating: 00.alumnes_practico/model/weights/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Define the labels and their combined index\n",
        "combined_labels = [\"1O\", \"1C\", \"1E\", \"1B\", \"2O\", \"2C\", \"2E\", \"2B\", \"3O\", \"3C\", \"3E\", \"3B\",\n",
        "                   \"4O\", \"4C\", \"4E\", \"4B\", \"5O\", \"5C\", \"5E\", \"5B\", \"6O\", \"6C\", \"6E\", \"6B\",\n",
        "                   \"7O\", \"7C\", \"7E\", \"7B\", \"8O\", \"8C\", \"8E\", \"8B\", \"9O\", \"9C\", \"9E\", \"9B\",\n",
        "                   \"10O\", \"10C\", \"10E\", \"10B\", \"11O\", \"11C\", \"11E\", \"11B\", \"12O\", \"12C\",\n",
        "                   \"12E\", \"12B\", \"J\"]\n",
        "\n",
        "# Define the labels\n",
        "number_labels = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12']\n",
        "suit_labels = ['O', 'C', 'E', 'B', 'J']\n",
        "\n",
        "# Function to preprocess images before classification\n",
        "def preprocess_image(image, target_size=(224, 224)):\n",
        "    image = cv2.resize(image, target_size)\n",
        "    # cv2_imshow(image)\n",
        "    image = image.astype('float32')\n",
        "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "    return image\n",
        "\n",
        "# output_image = image.copy()  # Copy image for drawing\n",
        "\n",
        "def inference_images(images, output_image_folder, output_annotation_folder, conf=0.25):\n",
        "\n",
        "  # Run YOLO inference\n",
        "  results = model.predict(images, conf=conf)\n",
        "  # Ensure the output image folder exists\n",
        "  os.makedirs(output_image_folder, exist_ok=True)\n",
        "\n",
        "  # Iterate over detected boxes\n",
        "  for i, result in enumerate(results):\n",
        "      # print(result)\n",
        "      boxes = result.boxes  # Bounding boxes\n",
        "      output_image = images[i].copy()  # Copy image for drawing\n",
        "\n",
        "      # Prepare annotation file\n",
        "      annotation_file = os.path.join(output_annotation_folder, f\"{os.path.splitext(os.path.basename(image_list[i]))[0]}.txt\")\n",
        "      with open(annotation_file, 'w') as f:\n",
        "          for box in boxes:\n",
        "              # Extract coordinates and normalize them\n",
        "              x_center, y_center, width, height = box.xywhn[0].cpu().numpy()\n",
        "\n",
        "              # Get the confidence score for the detection\n",
        "              confidence = box.conf.item()\n",
        "\n",
        "              # Crop the card from the original image\n",
        "              x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "              cropped_card = images[i][y1:y2, x1:x2]\n",
        "\n",
        "              # Preprocess the cropped card\n",
        "              preprocessed_card = preprocess_image(cropped_card)\n",
        "\n",
        "              # Run the classifier on the cropped card\n",
        "              predictions = classifier.predict(preprocessed_card)\n",
        "\n",
        "              # Extract number and suit predictions\n",
        "              number_prediction = predictions[0]\n",
        "              suit_prediction = predictions[1]\n",
        "\n",
        "              # Get the index of the highest probability for both tasks\n",
        "              predicted_number = np.argmax(number_prediction, axis=1)[0]\n",
        "              predicted_suit = np.argmax(suit_prediction, axis=1)[0]\n",
        "\n",
        "              # Handle Joker case where no number should be included\n",
        "              if suit_labels[predicted_suit] == 'J':\n",
        "                  combined_label = 'J'\n",
        "              else:\n",
        "                  combined_label = f\"{number_labels[predicted_number]}{suit_labels[predicted_suit]}\"\n",
        "\n",
        "              label_index = combined_labels.index(combined_label)\n",
        "\n",
        "              # Write to the annotation file in YOLO format with confidence\n",
        "              f.write(f\"{label_index} {x_center} {y_center} {width} {height} {confidence}\\n\")\n",
        "\n",
        "              # Draw bounding box on the image\n",
        "              cv2.rectangle(output_image, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=5)\n",
        "\n",
        "              # Put the label above the bounding box\n",
        "              cv2.putText(output_image, combined_label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                          fontScale=3, color=(0, 255, 0), thickness=3)\n",
        "\n",
        "      # Save the output image with bounding boxes in the specified folder\n",
        "      output_image_path = os.path.join(output_image_folder, f\"{os.path.splitext(os.path.basename(image_list[i]))[0]}_with_boxes.jpg\")\n",
        "      cv2.imwrite(output_image_path, output_image)\n"
      ],
      "metadata": {
        "id": "oWEzxlZLJhuq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inferencia sobre datos de test\n",
        "Reemplazar test_folder con la carpeta de sus imágenes"
      ],
      "metadata": {
        "id": "S91X9Vxped2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the output folder for the images with drawn bounding boxes\n",
        "output_image_folder = '/content/output_images/'\n",
        "\n",
        "test_folder = '/content/00.alumnes_practico/data/eval/images/val'\n",
        "image_list = glob.glob(f\"{test_folder}/*.jpg\")\n",
        "# Path for images and annotations\n",
        "# image_list = ['/content/test-cards-image2.jpg', '/content/test-cards-image.jpg']\n",
        "output_annotation_folder = '/content/annotations/'\n",
        "\n",
        "# Ensure the annotation folder exists\n",
        "os.makedirs(output_annotation_folder, exist_ok=True)\n",
        "\n",
        "# Load the images\n",
        "images = []\n",
        "for img_name in image_list:\n",
        "    image = cv2.imread(img_name)\n",
        "    images.append(image)\n",
        "\n",
        "inference_images(images, output_image_folder, output_annotation_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6zChAAfz0_S",
        "outputId": "124d3936-5f1b-4560-bd8d-f8d90f1c7401"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x640 2 cards, 5.3ms\n",
            "1: 640x640 3 cards, 5.3ms\n",
            "2: 640x640 3 cards, 5.3ms\n",
            "3: 640x640 3 cards, 5.3ms\n",
            "4: 640x640 2 cards, 5.3ms\n",
            "5: 640x640 2 cards, 5.3ms\n",
            "6: 640x640 3 cards, 5.3ms\n",
            "7: 640x640 1 card, 5.3ms\n",
            "8: 640x640 1 card, 5.3ms\n",
            "9: 640x640 3 cards, 5.3ms\n",
            "10: 640x640 2 cards, 5.3ms\n",
            "11: 640x640 1 card, 5.3ms\n",
            "12: 640x640 2 cards, 5.3ms\n",
            "13: 640x640 2 cards, 5.3ms\n",
            "14: 640x640 3 cards, 5.3ms\n",
            "15: 640x640 2 cards, 5.3ms\n",
            "16: 640x640 1 card, 5.3ms\n",
            "17: 640x640 2 cards, 5.3ms\n",
            "18: 640x640 2 cards, 5.3ms\n",
            "19: 640x640 1 card, 5.3ms\n",
            "20: 640x640 2 cards, 5.3ms\n",
            "21: 640x640 2 cards, 5.3ms\n",
            "22: 640x640 2 cards, 5.3ms\n",
            "23: 640x640 3 cards, 5.3ms\n",
            "24: 640x640 3 cards, 5.3ms\n",
            "25: 640x640 2 cards, 5.3ms\n",
            "26: 640x640 3 cards, 5.3ms\n",
            "27: 640x640 3 cards, 5.3ms\n",
            "28: 640x640 2 cards, 5.3ms\n",
            "29: 640x640 1 card, 5.3ms\n",
            "30: 640x640 1 card, 5.3ms\n",
            "31: 640x640 3 cards, 5.3ms\n",
            "Speed: 6.2ms preprocess, 5.3ms inference, 13.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Define the folder to be zipped and the name of the zip file\n",
        "folder_to_zip = '/content/output_images'\n",
        "zip_filename = '/content/output_images.zip'\n",
        "\n",
        "# Create a zip file\n",
        "shutil.make_archive(zip_filename.replace('.zip', ''), 'zip', folder_to_zip)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hCxZ7L7X5DCb",
        "outputId": "a00dccfb-40ab-47ab-f059-e47ba82b6ec6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/output_images.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conversión a formato de puntos de envido\n",
        "En este código se transforman las anotaciones al formato solicitado por los profesores."
      ],
      "metadata": {
        "id": "M3YXl3ZveqJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# Define the labels and their combined index\n",
        "combined_labels = [\"1O\", \"1C\", \"1E\", \"1B\", \"2O\", \"2C\", \"2E\", \"2B\", \"3O\", \"3C\", \"3E\", \"3B\",\n",
        "                   \"4O\", \"4C\", \"4E\", \"4B\", \"5O\", \"5C\", \"5E\", \"5B\", \"6O\", \"6C\", \"6E\", \"6B\",\n",
        "                   \"7O\", \"7C\", \"7E\", \"7B\", \"8O\", \"8C\", \"8E\", \"8B\", \"9O\", \"9C\", \"9E\", \"9B\",\n",
        "                   \"10O\", \"10C\", \"10E\", \"10B\", \"11O\", \"11C\", \"11E\", \"11B\", \"12O\", \"12C\",\n",
        "                   \"12E\", \"12B\", \"J\"]\n",
        "\n",
        "# Define the labels\n",
        "number_labels = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12']\n",
        "suit_labels = ['O', 'C', 'E', 'B', 'J']\n",
        "\n",
        "# Points calculation helper function\n",
        "def calculate_envido_points(cards):\n",
        "    # Filter out invalid cards\n",
        "    valid_cards = [card for card in cards if card in range(1, 8)]\n",
        "\n",
        "    if len(valid_cards) < 2:\n",
        "        return 0  # Not enough cards to calculate points\n",
        "\n",
        "    # Count occurrences of each card value\n",
        "    card_counts = {i: valid_cards.count(i) for i in range(1, 8)}\n",
        "\n",
        "    # Special case for cards 10, 11, 12\n",
        "    if card_counts.get(10, 0) >= 1 and card_counts.get(11, 0) >= 1:\n",
        "        return 20\n",
        "    if card_counts.get(10, 0) >= 1 and card_counts.get(12, 0) >= 1:\n",
        "        return 20\n",
        "    if card_counts.get(11, 0) >= 1 and card_counts.get(12, 0) >= 1:\n",
        "        return 20\n",
        "\n",
        "    # If there are more than 2 cards, take the two highest cards\n",
        "    if len(valid_cards) > 2:\n",
        "        valid_cards = sorted(valid_cards, reverse=True)[:2]\n",
        "\n",
        "    # Find the best possible pair\n",
        "    best_points = 0\n",
        "    for i in range(len(valid_cards)):\n",
        "        for j in range(i + 1, len(valid_cards)):\n",
        "            pair_sum = valid_cards[i] + valid_cards[j]\n",
        "            best_points = max(best_points, pair_sum)\n",
        "\n",
        "    # Add 20 to the sum for the final Envido points\n",
        "    return best_points + 20\n",
        "\n",
        "# Path to the folder containing YOLO annotation files\n",
        "annotation_folder = '/content/annotations'\n",
        "\n",
        "# Initialize the result dictionary\n",
        "result = {}\n",
        "\n",
        "# Iterate over the annotation files in the folder\n",
        "for annotation_file in os.listdir(annotation_folder):\n",
        "    if annotation_file.endswith('.txt'):\n",
        "        # Read the annotation file\n",
        "        file_path = os.path.join(annotation_folder, annotation_file)\n",
        "        with open(file_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        # Extract image name from file name\n",
        "        image_name = os.path.splitext(annotation_file)[0] + '.jpg'\n",
        "\n",
        "        # Initialize the data structure for the current image\n",
        "        image_data = {\n",
        "            \"total_cards\": 0,\n",
        "            \"cards\": {suit: [] for suit in suit_labels},\n",
        "            \"points\": 0,\n",
        "            \"figure\": \"N/A\"\n",
        "        }\n",
        "\n",
        "        # Process each line in the annotation file\n",
        "        for line in lines:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) < 6:\n",
        "                continue\n",
        "\n",
        "            label_index = int(parts[0])\n",
        "            x_center, y_center, width, height, confidence = map(float, parts[1:])\n",
        "\n",
        "            # Get the combined label from the index\n",
        "            combined_label = combined_labels[label_index]\n",
        "\n",
        "            # Extract the suit and number\n",
        "            if combined_label == 'J':\n",
        "                suit = 'J'\n",
        "                number = None\n",
        "            else:\n",
        "                number = int(combined_label[:-1])\n",
        "                suit = combined_label[-1]\n",
        "\n",
        "            # Update the data structure\n",
        "            if suit in image_data[\"cards\"]:\n",
        "                if number is not None:\n",
        "                    image_data[\"cards\"][suit].append(number)\n",
        "                image_data[\"total_cards\"] += 1\n",
        "\n",
        "        # Sort the numbers for each suit and compute points\n",
        "        for suit in image_data[\"cards\"]:\n",
        "            image_data[\"cards\"][suit] = sorted(image_data[\"cards\"][suit])\n",
        "            # Calculate Envido points for the suit\n",
        "            if suit != 'J':  # Exclude Joker suit\n",
        "                image_data[\"points\"] = max(image_data[\"points\"], calculate_envido_points(image_data[\"cards\"][suit]))\n",
        "\n",
        "        result[image_name] = image_data\n",
        "\n",
        "# Save the result dictionary to a JSON file\n",
        "with open('annotations_envido.json', 'w') as json_file:\n",
        "    json.dump(result, json_file, indent=4)\n",
        "\n",
        "print(\"Annotations with Envido points have been transformed and saved to 'annotations.json'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmoAM95zS9k-",
        "outputId": "453444b2-2cb1-4a22-df77-c5c4fcc89ca9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annotations with Envido points have been transformed and saved to 'annotations.json'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PRkzLYbjWZ_b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}